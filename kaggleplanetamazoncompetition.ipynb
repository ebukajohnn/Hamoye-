{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-03-22T10:34:03.539126Z","iopub.execute_input":"2022-03-22T10:34:03.539891Z","iopub.status.idle":"2022-03-22T10:34:03.589784Z","shell.execute_reply.started":"2022-03-22T10:34:03.539811Z","shell.execute_reply":"2022-03-22T10:34:03.589223Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n","metadata":{"execution":{"iopub.status.busy":"2022-03-22T10:34:03.592236Z","iopub.execute_input":"2022-03-22T10:34:03.592717Z","iopub.status.idle":"2022-03-22T10:34:03.595318Z","shell.execute_reply.started":"2022-03-22T10:34:03.592692Z","shell.execute_reply":"2022-03-22T10:34:03.594772Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"#inputting train csv\ntrain_classes = pd.read_csv('../input/content/train_v2.csv')\ntrain_classes.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-22T10:34:03.596093Z","iopub.execute_input":"2022-03-22T10:34:03.596245Z","iopub.status.idle":"2022-03-22T10:34:03.675272Z","shell.execute_reply.started":"2022-03-22T10:34:03.596224Z","shell.execute_reply":"2022-03-22T10:34:03.674678Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"labels = set()\ndef splitting_tags(tags):\n    for tag in tags.split():\n        labels.add(tag)\ntrain_classes1 = train_classes.copy()\ntrain_classes1['tags'].apply(splitting_tags)\nlabels = list(labels)\nprint(labels)\n\n\nassert len(train_classes1['image_name'].unique()) == train_classes1.shape[0]\n\nfor tag in labels:\n    train_classes1[tag] = train_classes1['tags'].apply(lambda x: 1 if tag in x.split() else 0)\n    \n\ntrain_classes1['image_name'] = train_classes1['image_name'].apply(lambda x: '{}.jpg'.format(x))\ntrain_classes1.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-22T10:34:03.676333Z","iopub.execute_input":"2022-03-22T10:34:03.676746Z","iopub.status.idle":"2022-03-22T10:34:04.153901Z","shell.execute_reply.started":"2022-03-22T10:34:03.676708Z","shell.execute_reply":"2022-03-22T10:34:04.153097Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, BatchNormalization, Conv2D, MaxPooling2D\nfrom tensorflow.keras.layers import Dropout, Flatten\nfrom tensorflow.keras.optimizers import Adam, SGD\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\n\ncolumns = list(train_classes1.columns[2:]) \ncolumns","metadata":{"execution":{"iopub.status.busy":"2022-03-22T10:34:04.155390Z","iopub.execute_input":"2022-03-22T10:34:04.155579Z","iopub.status.idle":"2022-03-22T10:34:08.903796Z","shell.execute_reply.started":"2022-03-22T10:34:04.155557Z","shell.execute_reply":"2022-03-22T10:34:08.903089Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"def fbeta(y_true, y_pred, beta = 2, epsilon = 1e-4):\n    \n    beta_squared = beta**2\n    \n    y_true = tf.cast(y_true, tf.float32)\n    y_pred = tf.cast(tf.greater(tf.cast(y_pred, tf.float32), tf.constant(0.5)), tf.float32)\n    \n    tp = tf.reduce_sum(y_true * y_pred, axis = 1)\n    fp = tf.reduce_sum(y_pred, axis = 1) - tp\n    fn = tf.reduce_sum(y_true, axis = 1) - tp\n    \n    precision = tp/(tp+fp+epsilon)\n    recall = tp/(tp+fn+epsilon)\n    \n    fb = (1+beta_squared)*precision*recall / (beta_squared*precision+recall+epsilon)\n    return fb","metadata":{"execution":{"iopub.status.busy":"2022-03-22T10:34:08.905075Z","iopub.execute_input":"2022-03-22T10:34:08.905431Z","iopub.status.idle":"2022-03-22T10:34:08.911888Z","shell.execute_reply.started":"2022-03-22T10:34:08.905397Z","shell.execute_reply":"2022-03-22T10:34:08.911383Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"def multi_label_acc(y_true, y_pred, epsilon = 1e-4):\n    \n    y_true = tf.cast(y_true, tf.float32)\n    y_pred = tf.cast(tf.greater(tf.cast(y_pred, tf.float32), tf.constant(0.5)), tf.float32)\n    \n    tp = tf.reduce_sum(y_true * y_pred, axis = 1)\n    fp = tf.reduce_sum(y_pred, axis = 1) - tp\n    fn = tf.reduce_sum(y_true, axis = 1) - tp\n    \n    y_true = tf.cast(y_true, tf.bool)\n    y_pred = tf.cast(y_pred, tf.bool)\n        \n    tn = tf.reduce_sum(tf.cast(tf.logical_not(y_true), tf.float32) * tf.cast(tf.logical_not(y_pred), tf.float32), \n                       axis = 1)\n    return (tp+tn)/(tp+tn+fp+fn+epsilon)","metadata":{"execution":{"iopub.status.busy":"2022-03-22T10:34:08.912867Z","iopub.execute_input":"2022-03-22T10:34:08.913212Z","iopub.status.idle":"2022-03-22T10:34:08.930773Z","shell.execute_reply.started":"2022-03-22T10:34:08.913183Z","shell.execute_reply":"2022-03-22T10:34:08.930329Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"def build_model():\n    model = Sequential()\n    model.add(BatchNormalization(input_shape=(128, 128, 3)))\n    model.add(Conv2D(32, kernel_size=(3, 3), padding='same', activation='relu'))\n    model.add(Conv2D(32, kernel_size=(3, 3), activation='relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    model.add(Dropout(0.2))\n\n    model.add(Conv2D(64, kernel_size=(3, 3), padding='same', activation='relu'))\n    model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    model.add(Dropout(0.2))\n\n    model.add(Conv2D(128, kernel_size=(3, 3), padding='same', activation='relu'))\n    model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    model.add(Dropout(0.2))\n\n    model.add(Conv2D(256, kernel_size=(3, 3), padding='same', activation='relu'))\n    model.add(Conv2D(256, kernel_size=(3, 3), activation='relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    model.add(Dropout(0.2))\n\n    model.add(Flatten())\n    model.add(Dense(512, activation='relu'))\n    model.add(Dropout(0.5))\n    model.add(Dense(17, activation='sigmoid'))\n\n    opt = Adam(lr=1e-4)\n\n    model.compile(loss='binary_crossentropy',\n              \n              optimizer=opt,\n              metrics=[multi_label_acc, fbeta])\n\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-03-22T10:34:08.932709Z","iopub.execute_input":"2022-03-22T10:34:08.933314Z","iopub.status.idle":"2022-03-22T10:34:08.942570Z","shell.execute_reply.started":"2022-03-22T10:34:08.933289Z","shell.execute_reply":"2022-03-22T10:34:08.941884Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# defining the metric value function\nfrom keras import backend\n\ndef fbeta(y_true, y_pred, beta=2):\n    #clip predictions\n    y_pred = backend.clip(y_pred, 0, 1)\n    # calculate elements\n    tp = backend.sum(backend.round(backend.clip(y_true * y_pred, 0, 1)), axis = 1)\n    fp = backend.sum(backend.round(backend.clip(y_true - y_pred, 0, 1)), axis = 1)\n    fn = backend.sum(backend.round(backend.clip(y_pred - y_true, 0, 1)), axis = 1)\n    \n    # calculate precision\n    p = tp/(tp + fp + backend.epsilon())\n    #calculate recall\n    r = tp / (tp + fn + backend.epsilon())\n    #calculate fbeta\n    bb = beta ** 2\n    fbeta_score = backend.mean((1+ bb) * (p * r)/ (bb * p + r + backend.epsilon()))\n    return fbeta_score","metadata":{"execution":{"iopub.status.busy":"2022-03-22T10:34:08.943447Z","iopub.execute_input":"2022-03-22T10:34:08.943873Z","iopub.status.idle":"2022-03-22T10:34:08.955868Z","shell.execute_reply.started":"2022-03-22T10:34:08.943849Z","shell.execute_reply":"2022-03-22T10:34:08.955305Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"train_datagen = ImageDataGenerator(featurewise_center = True)\n#                                   horizontal_flip = True,\n#                                   vertical_flip = True,\n#                                   rotation_range = 90)\nval_datagen = ImageDataGenerator(featurewise_center = True)\ntrain_datagen.mean = [123.68, 116.779, 103.939]\nval_datagen.mean= [123.68, 116.779, 103.939]","metadata":{"execution":{"iopub.status.busy":"2022-03-22T10:34:08.956666Z","iopub.execute_input":"2022-03-22T10:34:08.956825Z","iopub.status.idle":"2022-03-22T10:34:08.967687Z","shell.execute_reply.started":"2022-03-22T10:34:08.956805Z","shell.execute_reply":"2022-03-22T10:34:08.967158Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"columns","metadata":{"execution":{"iopub.status.busy":"2022-03-22T10:34:08.968493Z","iopub.execute_input":"2022-03-22T10:34:08.968645Z","iopub.status.idle":"2022-03-22T10:34:08.977418Z","shell.execute_reply.started":"2022-03-22T10:34:08.968625Z","shell.execute_reply":"2022-03-22T10:34:08.976900Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"#split the various tags in train_csv\ntrain_classes['splitted tags'] = train_classes['tags'].apply(lambda x: x.split())","metadata":{"execution":{"iopub.status.busy":"2022-03-22T10:34:08.978318Z","iopub.execute_input":"2022-03-22T10:34:08.978509Z","iopub.status.idle":"2022-03-22T10:34:09.009216Z","shell.execute_reply.started":"2022-03-22T10:34:08.978486Z","shell.execute_reply":"2022-03-22T10:34:09.008616Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# combine all tags into a set to know the unique number of tags\ncombine_list = []\nfor i, n in enumerate(train_classes['splitted tags']):\n    combine_list.extend(n)\ncombine_set = set(combine_list) \nlen(combine_set)","metadata":{"execution":{"iopub.status.busy":"2022-03-22T10:34:09.010309Z","iopub.execute_input":"2022-03-22T10:34:09.010495Z","iopub.status.idle":"2022-03-22T10:34:09.031202Z","shell.execute_reply.started":"2022-03-22T10:34:09.010472Z","shell.execute_reply":"2022-03-22T10:34:09.030650Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# building the train_labels\ncolumns = sorted(list(combine_set))\ntrain_labels = pd.DataFrame(np.zeros((40479, 17)), columns = columns)\ntrain_labels","metadata":{"execution":{"iopub.status.busy":"2022-03-22T10:34:09.032971Z","iopub.execute_input":"2022-03-22T10:34:09.033211Z","iopub.status.idle":"2022-03-22T10:34:09.065552Z","shell.execute_reply.started":"2022-03-22T10:34:09.033188Z","shell.execute_reply":"2022-03-22T10:34:09.065137Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"sample_submission = pd.read_csv('../input/content/sample_submission_v2.csv')\nsample_submission1 = sample_submission.copy()\nsample_submission1['image_name'] = sample_submission1['image_name'].apply(lambda x: '{}.jpg'.format(x))\nsample_submission1.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-22T10:34:09.066422Z","iopub.execute_input":"2022-03-22T10:34:09.066658Z","iopub.status.idle":"2022-03-22T10:34:09.161932Z","shell.execute_reply.started":"2022-03-22T10:34:09.066636Z","shell.execute_reply":"2022-03-22T10:34:09.161069Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"sample_submission.to_csv(\"submission.csv\",index=False,header=1)","metadata":{"execution":{"iopub.status.busy":"2022-03-22T10:51:35.311035Z","iopub.execute_input":"2022-03-22T10:51:35.311245Z","iopub.status.idle":"2022-03-22T10:51:35.392183Z","shell.execute_reply.started":"2022-03-22T10:51:35.311218Z","shell.execute_reply":"2022-03-22T10:51:35.391581Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}